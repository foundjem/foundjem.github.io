<!doctype html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: February 14, 2025 --><html lang="en-us" dir="ltr"
      data-wc-theme-default="system">
  
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="generator" content="Hugo Blox Builder 0.3.2" />

  
  












  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Armstrong Foundjem" />

  
  
  
    
  
  <meta name="description" content="Agentic AI Systems in Multi-Environment Settings 1. Introduction to Agentic AI An Agentic AI System refers to an autonomous AI system that can sense, decide, and act in an environment to achieve specific goals. In multi-environment settings, these AI agents operate across diverse, dynamic, and often conflicting environments, requiring adaptive decision-making, communication, and coordination.
" />

  
  <link rel="alternate" hreflang="en-us" href="http://localhost:1313/project/agentic/" />

  
  
  
  
    
    <link rel="stylesheet" href="/css/themes/emerald.min.css" />
  

  
  
    
    <link href="/dist/wc.min.05570f1deda629d4e2d77f73534a63aa04471f012db6735c59424372f467db85.css" rel="stylesheet" />
  

  
  
  

  

  <script>
     
    window.hbb = {
       defaultTheme: document.documentElement.dataset.wcThemeDefault,
       setDarkTheme: () => {
        document.documentElement.classList.add("dark");
        document.documentElement.style.colorScheme = "dark";
      },
       setLightTheme: () => {
        document.documentElement.classList.remove("dark");
        document.documentElement.style.colorScheme = "light";
      }
    }

    console.debug(`Default Hugo Blox Builder theme is ${window.hbb.defaultTheme}`);

    if ("wc-color-theme" in localStorage) {
      localStorage.getItem("wc-color-theme") === "dark" ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
    } else {
      window.hbb.defaultTheme === "dark" ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
      if (window.hbb.defaultTheme === "system") {
        window.matchMedia("(prefers-color-scheme: dark)").matches ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
      }
    }
  </script>

  <script>
    
    document.addEventListener('DOMContentLoaded', function () {
      
      let checkboxes = document.querySelectorAll('li input[type=\'checkbox\'][disabled]');
      checkboxes.forEach(e => {
        e.parentElement.parentElement.classList.add('task-list');
      });

      
      const liNodes = document.querySelectorAll('.task-list li');
      liNodes.forEach(nodes => {
        let textNodes = Array.from(nodes.childNodes).filter(node => node.nodeType === 3 && node.textContent.trim().length > 1);
        if (textNodes.length > 0) {
          const span = document.createElement('label');
          textNodes[0].after(span);  
          span.appendChild(nodes.querySelector('input[type=\'checkbox\']'));
          span.appendChild(textNodes[0]);
        }
      });
    });
  </script>

  
  
  




































  
  

  
  <link rel="icon" type="image/png" href="/media/icon_hu_5cac115d14ed3d49.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu_e7f327b39c12e7ca.png" />

  <link rel="canonical" href="http://localhost:1313/project/agentic/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
    <meta property="twitter:site" content="@GetResearchDev" />
    <meta property="twitter:creator" content="@GetResearchDev" />
  
  <meta property="og:site_name" content="Hugo Academic CV Theme" />
  <meta property="og:url" content="http://localhost:1313/project/agentic/" />
  <meta property="og:title" content="Multi-Agent AI Systems | Hugo Academic CV Theme" />
  <meta property="og:description" content="Agentic AI Systems in Multi-Environment Settings
1. Introduction to Agentic AI
An Agentic AI System refers to an autonomous AI system that can sense, decide, and act in an environment to achieve specific goals. In multi-environment settings, these AI agents operate across diverse, dynamic, and often conflicting environments, requiring adaptive decision-making, communication, and coordination." /><meta property="og:image" content="http://localhost:1313/project/agentic/featured.png" />
    <meta property="twitter:image" content="http://localhost:1313/project/agentic/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2025-02-11T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2025-02-11T00:00:00&#43;00:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/project/agentic/"
  },
  "headline": "Multi-Agent AI Systems",
  
  "image": [
    "http://localhost:1313/project/agentic/featured.png"
  ],
  
  "datePublished": "2025-02-11T00:00:00Z",
  "dateModified": "2025-02-11T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Armstrong Foundjem"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Hugo Academic CV Theme",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/media/icon_hu_1df060215326dd50.png"
    }
  },
  "description": "\u003ch1 id=\"agentic-ai-systems-in-multi-environment-settings\"\u003e\u003cstrong\u003eAgentic AI Systems in Multi-Environment Settings\u003c/strong\u003e\u003c/h1\u003e\n\u003ch4 id=\"1-introduction-to-agentic-ai\"\u003e\u003cstrong\u003e1. Introduction to Agentic AI\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eAn \u003cstrong\u003eAgentic AI System\u003c/strong\u003e refers to an autonomous AI system that can sense, decide, and act in an environment to achieve specific goals. In \u003cstrong\u003emulti-environment settings\u003c/strong\u003e, these AI agents operate across diverse, dynamic, and often conflicting environments, requiring \u003cstrong\u003eadaptive decision-making, communication, and coordination\u003c/strong\u003e.\u003c/p\u003e"
}
</script>

  

  


  <title>Multi-Agent AI Systems | Hugo Academic CV Theme</title>

  
  
  
  
  
    
    
  
  
  <style>
    @font-face {
      font-family: 'Inter var';
      font-style: normal;
      font-weight: 100 900;
      font-display: swap;
      src: url(/dist/font/Inter.var.woff2) format(woff2);
    }
  </style>

  

  
  


  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
  
  
  
  
  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
  
  
  
  
  
  
  
  
  
  
  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  







<link type="text/css" rel="stylesheet" href="/dist/pagefind/pagefind-ui.be766eb419317a14ec769d216e9779bfe8f3737c80e780f4ba0dafb57a41a482.css" integrity="sha256-vnZutBkxehTsdp0hbpd5v&#43;jzc3yA54D0ug2vtXpBpII=" />


<script src="/dist/pagefind/pagefind-ui.87693d7c6f2b3b347ce359d0ede762c033419f0a32b22ce508c335a81d841f1b.js" integrity="sha256-h2k9fG8rOzR841nQ7ediwDNBnwoysizlCMM1qB2EHxs="></script>


<script>window.hbb.pagefind = {"baseUrl":"/"};</script>

<style>
  html.dark {
    --pagefind-ui-primary: #eeeeee;
    --pagefind-ui-text: #eeeeee;
    --pagefind-ui-background: #152028;
    --pagefind-ui-border: #152028;
    --pagefind-ui-tag: #152028;
  }

   
  .search-close > svg {
    height: calc(64px * var(--pagefind-ui-scale));
    width: calc(64px * var(--pagefind-ui-scale));
  }
</style>

<script>
  
  let searchWrapper = null;

  window.addEventListener('DOMContentLoaded', (event) => {
    
    new PagefindUI({
      element: "#search",
      showSubResults: true,
      baseUrl: window.hbb.pagefind.baseUrl,
      bundlePath: window.hbb.pagefind.baseUrl + "pagefind/",
    });

    
    searchWrapper = document.getElementById('search-wrapper');

    
    let triggers = document.querySelectorAll('[data-search-toggle]');
    triggers.forEach(trigger =>
      trigger.addEventListener('click', handleSearchToggle)
    );
  });

  function handleSearchToggle(event) {
    if (!searchWrapper) return;

    const isHidden = searchWrapper.classList.contains('hidden');
    searchWrapper.classList.toggle('hidden');
    document.body.style.overflow = isHidden ? 'hidden' : '';

    const searchInput = searchWrapper.querySelector("input");
    if (searchInput) {
      searchInput.value = "";
      searchInput.focus();
    }

    if (!searchWrapper.classList.contains('hidden')) {
      let clearTrigger = document.querySelector('.pagefind-ui__search-clear');

      if (clearTrigger && !clearTrigger.hasAttribute('listenerOnClick')) {
        clearTrigger.setAttribute('listenerOnClick', 'true');

        clearTrigger.addEventListener('click', () => {
          searchInput.focus();
        });
      }
    }
  }

  
  document.addEventListener('keydown', (event) => {
    if (event.key === 'Escape' && searchWrapper && !searchWrapper.classList.contains('hidden')) {
      searchWrapper.classList.add('hidden');
    }
  });
</script>















  
  
  
  
  
  
  
  <script
    defer
    src="/js/hugo-blox-en.min.js"
    integrity=""
  ></script>

  
  








  
    
      
      <script async defer src="https://buttons.github.io/buttons.js"></script>

      
    
  




</head>

  <body class="dark:bg-hb-dark dark:text-white page-wrapper" id="top">
    <div id="page-bg"></div>
    <div class="page-header sticky top-0 z-30">
      
      
      
        
        
        
          <header id="site-header" class="header">
  <nav class="navbar px-3 flex justify-left">
    <div class="order-0 h-100">
      
      <a class="navbar-brand" href="/" title="Hugo Academic CV Theme">
        InSeco
      </a>
    </div>
    
    <input id="nav-toggle" type="checkbox" class="hidden" />
    <label
      for="nav-toggle"
      class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1">
      <svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20">
        <title>Open Menu</title>
        <path d="M0 3h20v2H0V3z m0 6h20v2H0V9z m0 6h20v2H0V0z"></path>
      </svg>
      <svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20">
        <title>Close Menu</title>
        <polygon
          points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2"
          transform="rotate(45 10 10)"></polygon>
      </svg>
    </label>
    

    
    
    <ul
      id="nav-menu"
      class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8 justify-left
      ">
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/"
        >Bio</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/experience/"
        >Experience</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/#papers"
        >Publications</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/event/"
        >Talks</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/post/"
        >Post</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/projects/"
        >Projects</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/teaching/"
        >Teaching</a
        >
      </li>
      
      
      
    </ul>

    <div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0">

      
      
      
      <button
        aria-label="toggle search"
        class="text-black hover:text-primary  inline-block px-3 text-xl dark:text-white"
        data-search-toggle>
        <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 512 512" fill="currentColor"><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352a144 144 0 1 0 0-288 144 144 0 1 0 0 288z"/></svg>
      </button>
      

      
      
      <div class="px-3 text-black hover:text-primary-700 dark:text-white dark:hover:text-primary-300
            [&.active]:font-bold [&.active]:text-black/90 dark:[&.active]:text-white">
        <button class="theme-toggle mt-1" accesskey="t" title="appearance">
          <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
               stroke-linejoin="round" class="dark:hidden">
            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
          </svg>
          <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
               stroke-linejoin="round" class=" dark:block [&:not(dark)]:hidden">
            <circle cx="12" cy="12" r="5"></circle>
            <line x1="12" y1="1" x2="12" y2="3"></line>
            <line x1="12" y1="21" x2="12" y2="23"></line>
            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
            <line x1="1" y1="12" x2="3" y2="12"></line>
            <line x1="21" y1="12" x2="23" y2="12"></line>
            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
          </svg>
        </button>
      </div>
      

      
      

      
      
    </div>
  </nav>
</header>

<div
  id="search-wrapper"
  class="hidden fixed inset-0 z-50 bg-white dark:bg-gray-900 flex flex-col overflow-hidden"
>
  <div class="flex justify-end p-3">
    <button
      aria-label="search"
      class="search-close text-black hover:text-primary dark:text-white"
      data-search-toggle
    >
      <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="size-6">
        <path stroke-linecap="round" stroke-linejoin="round" d="M6 18 18 6M6 6l12 12" />
      </svg>
    </button>
  </div>

  <div id="search" class="flex-1 overflow-y-auto p-3">
    
  </div>
</div>


        
      
    </div>
    <div class="page-body  my-10">
      





<div class="mx-auto flex max-w-screen-xl">
  



<aside class="hb-sidebar-container max-lg:[transform:translate3d(0,-100%,0)] lg:hidden xl:block">
  
  <div class="px-4 pt-4 lg:hidden">
    
    
  </div>
  <div class="hb-scrollbar lg:h-[calc(100vh-var(--navbar-height))]">
    <ul class="flex flex-col gap-1 lg:hidden">
      
      
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/event/"
    
  >Recent Talks
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/event/openinfra25/"
    
  >Leveraging OpenInfra and Open Source GenAI to Address Climate Change
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/event/openinfra23/"
    
  >How large language and deep learning models can prevent toxicity such as unconscious biases
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/event/fse21/"
    
  >ESEC/FSE21 --- Release Synchronization in Software Ecosystems
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/event/icse21/"
    
  >ICSE&#39;21 --- Onboarding vs. Diversity, Productivity and Quality ‚Äî Empirical Study of the OpenStack Ecosystem
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/event/podcast/"
    
  >CHAOSScast
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/event/icst17/"
    
  >ICST&#39;17 ---Broadcast vs. Unicast Review Technology: Does It Matter?
    </a>
              
            </li></ul>
      </div></li>
        <li class="open"><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/"
    
  >Projects
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col open"><a
    class="hb-sidebar-custom-link
      sidebar-active-item bg-primary-100 font-semibold text-primary-800 dark:bg-primary-300 dark:text-primary-900"
    href="/project/agentic/"
    
  >Multi-Agent AI Systems
    </a>
  
    <ul class="hb-sidebar-mobile-toc"><li>
              <a
                href="#"
                class="hb-docs-link"
              ></a>
            </li>
          <li>
              <a
                href="#2-key-characteristics-of-agentic-ai-in-multi-environment-systems"
                class="hb-docs-link"
              >&lt;strong&gt;2. Key Characteristics of Agentic AI in Multi-Environment Systems&lt;/strong&gt;</a>
            </li>
          <li>
              <a
                href="#3-types-of-multi-environment-settings"
                class="hb-docs-link"
              >&lt;strong&gt;3. Types of Multi-Environment Settings&lt;/strong&gt;</a>
            </li>
          <li>
              <a
                href="#4-architectural-models-for-multi-environment-ai-systems"
                class="hb-docs-link"
              >&lt;strong&gt;4. Architectural Models for Multi-Environment AI Systems&lt;/strong&gt;</a>
            </li>
          <li>
              <a
                href="#5-security-and-trust-in-agentic-ai"
                class="hb-docs-link"
              >&lt;strong&gt;5. Security and Trust in Agentic AI&lt;/strong&gt;</a>
            </li>
          <li>
              <a
                href="#6-real-world-applications-of-agentic-ai-in-multi-environment-systems"
                class="hb-docs-link"
              >&lt;strong&gt;6. Real-World Applications of Agentic AI in Multi-Environment Systems&lt;/strong&gt;</a>
            </li>
          <li>
              <a
                href="#7-conclusion"
                class="hb-docs-link"
              >&lt;strong&gt;7. Conclusion&lt;/strong&gt;</a>
            </li>
          <li>
              <a
                href="#conclusion"
                class="hb-docs-link"
              >&lt;strong&gt;Conclusion&lt;/strong&gt;</a>
            </li>
          </ul>
  
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/climate-change/"
    
  >Climate change
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/toxicity/"
    
  >Toxicity and unconcious bias
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/projects/"
    
  >Projects
    </a></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/"
    
  >Publications
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/openja-2024-empirical/"
    
  >An empirical study of testing machine learning in the wild
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/taraghi-2024-deep/"
    
  >Deep learning model reuse in the huggingface community: Challenges, benefit and trends
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/foundjem-2023-grounded/"
    
  >A Grounded Theory of Cross-community SECOs: Feedback Diversity vs. Synchronization
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/openja-2023-studying/"
    
  >Studying the Practices of Testing Machine Learning Software in the Wild
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/foundjem-2022-mixed/"
    
  >A mixed-methods analysis of micro-collaborative coding practices in OpenStack
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/foundjem-2022-software/"
    
  >Software Ecosystem Sustainability, a Socio-Technical Perspective
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/foundjem-2021-open/"
    
  >An open dataset for onboarding new contributors: empirical study of openstack ecosystem
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/foundjem-2021-onboarding/"
    
  >Onboarding vs. diversity, productivity and quality‚Äîempirical study of the openstack ecosystem
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/armstrong-2021-release/"
    
  >Release synchronization in software ecosystems
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/foundjem-2021-release/"
    
  >Release synchronization in software ecosystems: Empirical Study on OpenStack
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/foundjem-2020-cross/"
    
  >Cross-distribution feedback in software ecosystems
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/foundjem-2019-release/"
    
  >Release synchronization in software ecosystems
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/armstrong-2017-broadcast/"
    
  >Broadcast vs. unicast review technology: Does it matter?
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/foundjem-2017-towards/"
    
  >Towards improving the reliability of live migration operations in OpenStack clouds
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/"
    
  >Blogging Techky
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/get-started/"
    
  >üéâ Easily create your own simple yet highly customizable blog
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/second-brain/"
    
  >üß† Sharpen your thinking with a second brain
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/data-visualization/"
    
  >üìà Communicate your results effectively with the best data visualizations
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/teach-courses/"
    
  >üë©üèº‚Äçüè´ Teaching technical Skills
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/project-management/"
    
  >‚úÖ Manage your projects
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/experience/"
    
  >Experience
    </a></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/teaching/"
    
  >Teaching
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/teaching/quality-eng/"
    
  >Software Quality Engineering
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/teaching/security/"
    
  >Cloud Security
    </a>
              
            </li></ul>
      </div></li>
    </ul>

    <div class="max-xl:hidden h-0 w-64 shrink-0"></div></div>

</aside>
  

<nav class="hb-toc order-last hidden w-64 shrink-0 xl:block print:hidden px-4" aria-label="table of contents">
  











  <div class="hb-scrollbar text-sm [hyphens:auto] sticky top-16 overflow-y-auto pr-4 pt-6 max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] -mr-4 rtl:-ml-4"><p class="mb-4 font-semibold tracking-tight">On this page</p><ul>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#1-introduction-to-agentic-ai">1. Introduction to Agentic AI</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#2-key-characteristics-of-agentic-ai-in-multi-environment-systems">2. Key Characteristics of Agentic AI in Multi-Environment Systems</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#3-types-of-multi-environment-settings">3. Types of Multi-Environment Settings</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#31-homogeneous-vs-heterogeneous-environments">3.1. Homogeneous vs. Heterogeneous Environments</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#32-static-vs-dynamic-environments">3.2. Static vs. Dynamic Environments</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#33-cooperative-vs-competitive-multi-agent-environments">3.3. Cooperative vs. Competitive Multi-Agent Environments</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#34-fully-observable-vs-partially-observable-environments">3.4. Fully Observable vs. Partially Observable Environments</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#4-architectural-models-for-multi-environment-ai-systems">4. Architectural Models for Multi-Environment AI Systems</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#41-multi-agent-reinforcement-learning-marl">4.1. Multi-Agent Reinforcement Learning (MARL)</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#42-decentralized-partially-observable-markov-decision-processes-dec-pomdp">4.2. Decentralized Partially Observable Markov Decision Processes (Dec-POMDP)</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#43-federated-learning-for-distributed-ai-agents">4.3. Federated Learning for Distributed AI Agents</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#5-security-and-trust-in-agentic-ai">5. Security and Trust in Agentic AI</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#51-adversarial-ai-attacks">5.1. Adversarial AI Attacks</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#52-trust-models">5.2. Trust Models</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#6-real-world-applications-of-agentic-ai-in-multi-environment-systems">6. Real-World Applications of Agentic AI in Multi-Environment Systems</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#7-conclusion">7. Conclusion</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#1-multi-agent-reinforcement-learning-marl">1. Multi-Agent Reinforcement Learning (MARL)</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#environment">Environment:</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#code">Code:</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#explanation">Explanation:</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#2-game-theory-based-multi-agent-decision-making">2. Game Theory-Based Multi-Agent Decision Making</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#explanation-1">Explanation:</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#3-decentralized-multi-agent-system-with-communication">3. Decentralized Multi-Agent System with Communication</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#explanation-2">Explanation:</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#4-reinforcement-learning-for-multi-agent-traffic-control">4. Reinforcement Learning for Multi-Agent Traffic Control</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#explanation-3">Explanation:</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#conclusion">Conclusion</a>
      </li></ul>

  
  
    
    
  



    












  </div>
  </nav>


  <article class="w-full break-words flex min-h-[calc(100vh-var(--navbar-height))] min-w-0 justify-center pb-8 pr-[calc(env(safe-area-inset-right)-1.5rem)]">
    <main class="w-full min-w-0 max-w-6xl px-6 pt-4 md:px-12">

      

      <h1 class="mt-2 text-4xl font-bold tracking-tight text-slate-900 dark:text-slate-100">Multi-Agent AI Systems</h1>

      <div class="mt-4 mb-16">
      <div class="text-gray-500 dark:text-gray-300 text-sm flex items-center flex-wrap gap-y-2"><span class="mr-1">Feb 11, 2025</span>
        

        
        <span class="mx-1">¬∑</span>
        <span class="mx-1">
          7 min read
        </span>
        
        </div>

        <div class="mt-3">
          





        </div>
      </div>



      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      <div class="article-header article-container featured-image-wrapper mt-4 mb-16" style="max-width: 394px; max-height: 351px;">
        <div style="position: relative">
          <img src="/project/agentic/featured_hu_ecaabe9f8296f1fc.webp" width="394" height="351" alt="" class="featured-image">
          
        </div>
      </div>
      

      
      

      <div class="prose prose-slate lg:prose-xl dark:prose-invert">
        <h1 id="agentic-ai-systems-in-multi-environment-settings"><strong>Agentic AI Systems in Multi-Environment Settings</strong></h1>
<h4 id="1-introduction-to-agentic-ai"><strong>1. Introduction to Agentic AI</strong></h4>
<p>An <strong>Agentic AI System</strong> refers to an autonomous AI system that can sense, decide, and act in an environment to achieve specific goals. In <strong>multi-environment settings</strong>, these AI agents operate across diverse, dynamic, and often conflicting environments, requiring <strong>adaptive decision-making, communication, and coordination</strong>.</p>
<hr>
<h2 id="2-key-characteristics-of-agentic-ai-in-multi-environment-systems"><strong>2. Key Characteristics of Agentic AI in Multi-Environment Systems</strong></h2>
<ol>
<li><strong>Autonomy</strong> ‚Äì Operates independently with minimal human intervention.</li>
<li><strong>Adaptability</strong> ‚Äì Adjusts behavior based on real-time environmental changes.</li>
<li><strong>Multi-Agent Coordination</strong> ‚Äì Collaborates or competes with other agents.</li>
<li><strong>Distributed Decision-Making</strong> ‚Äì Decentralized intelligence for resilience.</li>
<li><strong>Goal-Oriented Optimization</strong> ‚Äì Maximizes rewards while minimizing risks.</li>
</ol>
<hr>
<h2 id="3-types-of-multi-environment-settings"><strong>3. Types of Multi-Environment Settings</strong></h2>
<h3 id="31-homogeneous-vs-heterogeneous-environments"><strong>3.1. Homogeneous vs. Heterogeneous Environments</strong></h3>
<ul>
<li><strong>Homogeneous Environments</strong>: AI agents operate in uniform conditions (e.g., cloud-based automation).</li>
<li><strong>Heterogeneous Environments</strong>: Agents interact in mixed conditions with different rules, constraints, and uncertainties (e.g., cyber-physical systems).</li>
</ul>
<h3 id="32-static-vs-dynamic-environments"><strong>3.2. Static vs. Dynamic Environments</strong></h3>
<ul>
<li><strong>Static Environments</strong>: Rules and conditions remain constant (e.g., financial AI trading models).</li>
<li><strong>Dynamic Environments</strong>: Conditions evolve over time (e.g., self-driving cars in urban traffic).</li>
</ul>
<h3 id="33-cooperative-vs-competitive-multi-agent-environments"><strong>3.3. Cooperative vs. Competitive Multi-Agent Environments</strong></h3>
<ul>
<li><strong>Cooperative</strong>: AI agents work together towards a shared goal (e.g., swarm robotics in disaster response).</li>
<li><strong>Competitive</strong>: AI agents compete against each other (e.g., adversarial cybersecurity AI).</li>
</ul>
<h3 id="34-fully-observable-vs-partially-observable-environments"><strong>3.4. Fully Observable vs. Partially Observable Environments</strong></h3>
<ul>
<li><strong>Fully Observable</strong>: AI agents have complete visibility (e.g., chess AI).</li>
<li><strong>Partially Observable</strong>: AI agents make decisions with limited information (e.g., autonomous drones in complex terrain).</li>
</ul>
<hr>
<h2 id="4-architectural-models-for-multi-environment-ai-systems"><strong>4. Architectural Models for Multi-Environment AI Systems</strong></h2>
<h3 id="41-multi-agent-reinforcement-learning-marl"><strong>4.1. Multi-Agent Reinforcement Learning (MARL)</strong></h3>
<ul>
<li>Agents learn optimal strategies through interaction and rewards.</li>
<li><strong>Mathematical Model:</strong>
\[
  Q(s, a) = (1 - \alpha) Q(s, a) + \alpha [R + \gamma \max_{a'} Q(s', a')]
  \]
<ul>
<li>\( Q(s, a) \): Expected reward for action \( a \) in state \( s \)</li>
<li>\( \alpha \): Learning rate</li>
<li>\( R \): Immediate reward</li>
<li>\( \gamma \): Discount factor for future rewards</li>
</ul>
</li>
</ul>
<h3 id="42-decentralized-partially-observable-markov-decision-processes-dec-pomdp"><strong>4.2. Decentralized Partially Observable Markov Decision Processes (Dec-POMDP)</strong></h3>
<ul>
<li>Used in <strong>multi-agent scenarios</strong> with uncertainty.</li>
<li>Each agent \( i \) has a policy \( \pi_i \) that maps local observations \( o_i \) to actions \( a_i \).</li>
<li><strong>Mathematical Model:</strong>
\[
  \pi_i(o_i) = \arg \max_{a_i} \sum_{t} \gamma^t R_i(s_t, a_t)
  \]</li>
</ul>
<h3 id="43-federated-learning-for-distributed-ai-agents"><strong>4.3. Federated Learning for Distributed AI Agents</strong></h3>
<ul>
<li>Agents <strong>collaborate</strong> by training models locally and sharing updates.</li>
<li><strong>Mathematical Model:</strong>
\[
  w_{t+1} = w_t - \eta \nabla F(w_t)
  \]
<ul>
<li>\( w_t \): Model weights at time \( t \)</li>
<li>\( \eta \): Learning rate</li>
<li>\( \nabla F(w_t) \): Gradient of the loss function</li>
</ul>
</li>
</ul>
<hr>
<h2 id="5-security-and-trust-in-agentic-ai"><strong>5. Security and Trust in Agentic AI</strong></h2>
<h3 id="51-adversarial-ai-attacks"><strong>5.1. Adversarial AI Attacks</strong></h3>
<ul>
<li><strong>Evasion Attacks</strong>: Fooling agents using adversarial examples.</li>
<li><strong>Poisoning Attacks</strong>: Manipulating training data to corrupt decision-making.</li>
</ul>
<h3 id="52-trust-models"><strong>5.2. Trust Models</strong></h3>
<ul>
<li>Trust is modeled using <strong>Bayesian belief networks</strong>:
\[
  P(T | E) = \frac{P(E | T) P(T)}{P(E)}
  \]
where \( P(T | E) \) is the trust probability given evidence \( E \).</li>
</ul>
<hr>
<h2 id="6-real-world-applications-of-agentic-ai-in-multi-environment-systems"><strong>6. Real-World Applications of Agentic AI in Multi-Environment Systems</strong></h2>
<ol>
<li><strong>Autonomous Vehicles</strong> ‚Äì Navigate in <strong>dynamic, multi-agent</strong> urban traffic.</li>
<li><strong>Cybersecurity AI</strong> ‚Äì Detect threats in <strong>partially observable</strong> network environments.</li>
<li><strong>Healthcare AI</strong> ‚Äì <strong>Federated learning</strong> for personalized medicine.</li>
<li><strong>Financial AI Trading</strong> ‚Äì <strong>Reinforcement learning-based</strong> market strategies.</li>
<li><strong>Smart Grid Energy Management</strong> ‚Äì Adaptive <strong>multi-agent</strong> optimization.</li>
</ol>
<hr>
<h2 id="7-conclusion"><strong>7. Conclusion</strong></h2>
<p>Agentic AI in multi-environment settings requires:</p>
<ul>
<li><strong>Adaptive learning models</strong> (MARL, Dec-POMDP).</li>
<li><strong>Distributed decision-making</strong> (Federated AI).</li>
<li><strong>Security mechanisms</strong> (Trust models, Adversarial AI).
These <strong>autonomous systems</strong> will drive the future of <strong>self-learning, secure, and efficient AI ecosystems</strong>. üöÄ</li>
</ul>
<hr>
<h3 id="1-multi-agent-reinforcement-learning-marl"><strong>1. Multi-Agent Reinforcement Learning (MARL)</strong></h3>
<p>This example implements <strong>Q-learning</strong> for two agents navigating a grid environment.</p>
<h4 id="environment"><strong>Environment:</strong></h4>
<ul>
<li>A <strong>5x5 grid</strong> where two agents must reach their respective goals.</li>
<li><strong>Reward:</strong> +10 for reaching the goal, -1 for illegal moves.</li>
<li><strong>Agents learn simultaneously using Q-learning</strong>.</li>
</ul>
<h4 id="code"><strong>Code:</strong></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">random</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Environment settings</span>
</span></span><span class="line"><span class="cl"><span class="n">GRID_SIZE</span> <span class="o">=</span> <span class="mi">5</span>
</span></span><span class="line"><span class="cl"><span class="n">ACTIONS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;UP&#34;</span><span class="p">,</span> <span class="s2">&#34;DOWN&#34;</span><span class="p">,</span> <span class="s2">&#34;LEFT&#34;</span><span class="p">,</span> <span class="s2">&#34;RIGHT&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">ACTION_MAP</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;UP&#34;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">&#34;DOWN&#34;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">&#34;LEFT&#34;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="s2">&#34;RIGHT&#34;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Agents start at random positions, goals at fixed points</span>
</span></span><span class="line"><span class="cl"><span class="n">AGENT_1_GOAL</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">AGENT_2_GOAL</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Q-tables for agents</span>
</span></span><span class="line"><span class="cl"><span class="n">Q_agent1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">GRID_SIZE</span><span class="p">,</span> <span class="n">GRID_SIZE</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ACTIONS</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl"><span class="n">Q_agent2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">GRID_SIZE</span><span class="p">,</span> <span class="n">GRID_SIZE</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ACTIONS</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Hyperparameters</span>
</span></span><span class="line"><span class="cl"><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Learning rate</span>
</span></span><span class="line"><span class="cl"><span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.9</span>  <span class="c1"># Discount factor</span>
</span></span><span class="line"><span class="cl"><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Exploration rate</span>
</span></span><span class="line"><span class="cl"><span class="n">episodes</span> <span class="o">=</span> <span class="mi">5000</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Function to get next position</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">move</span><span class="p">(</span><span class="n">position</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">new_position</span> <span class="o">=</span> <span class="p">(</span><span class="n">position</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ACTION_MAP</span><span class="p">[</span><span class="n">action</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">position</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">ACTION_MAP</span><span class="p">[</span><span class="n">action</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">new_position</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">GRID_SIZE</span> <span class="ow">and</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">new_position</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">GRID_SIZE</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">new_position</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">position</span>  <span class="c1"># Invalid moves stay in place</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Training loop</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">episodes</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">agent1_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">GRID_SIZE</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">GRID_SIZE</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">agent2_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">GRID_SIZE</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">GRID_SIZE</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">while</span> <span class="n">agent1_pos</span> <span class="o">!=</span> <span class="n">AGENT_1_GOAL</span> <span class="ow">or</span> <span class="n">agent2_pos</span> <span class="o">!=</span> <span class="n">AGENT_2_GOAL</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">agent</span><span class="p">,</span> <span class="n">Q_table</span><span class="p">,</span> <span class="n">goal</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Q_agent1</span><span class="p">,</span> <span class="n">AGENT_1_GOAL</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">Q_agent2</span><span class="p">,</span> <span class="n">AGENT_2_GOAL</span><span class="p">)]:</span>
</span></span><span class="line"><span class="cl">            <span class="n">pos</span> <span class="o">=</span> <span class="n">agent1_pos</span> <span class="k">if</span> <span class="n">agent</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">agent2_pos</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">pos</span> <span class="o">==</span> <span class="n">goal</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">continue</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># Choose action (Œµ-greedy)</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">action</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">ACTIONS</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">action</span> <span class="o">=</span> <span class="n">ACTIONS</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q_table</span><span class="p">[</span><span class="n">pos</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pos</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:])]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># Move agent</span>
</span></span><span class="line"><span class="cl">            <span class="n">new_pos</span> <span class="o">=</span> <span class="n">move</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">reward</span> <span class="o">=</span> <span class="mi">10</span> <span class="k">if</span> <span class="n">new_pos</span> <span class="o">==</span> <span class="n">goal</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># Update Q-table</span>
</span></span><span class="line"><span class="cl">            <span class="n">Q_table</span><span class="p">[</span><span class="n">pos</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pos</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ACTIONS</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">action</span><span class="p">)]</span> <span class="o">+=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">reward</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Q_table</span><span class="p">[</span><span class="n">new_pos</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new_pos</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:])</span> <span class="o">-</span> <span class="n">Q_table</span><span class="p">[</span><span class="n">pos</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pos</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ACTIONS</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">action</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># Update agent position</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">agent</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">agent1_pos</span> <span class="o">=</span> <span class="n">new_pos</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">agent2_pos</span> <span class="o">=</span> <span class="n">new_pos</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Training complete! Agents have learned optimal paths.&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="explanation"><strong>Explanation:</strong></h4>
<ul>
<li><strong>Two agents learn independently</strong> using <strong>Q-learning</strong>.</li>
<li><strong>Grid-based movement</strong>, avoiding invalid moves.</li>
<li><strong>Goal-oriented reinforcement learning</strong>.</li>
</ul>
<hr>
<h3 id="2-game-theory-based-multi-agent-decision-making"><strong>2. Game Theory-Based Multi-Agent Decision Making</strong></h3>
<p>This example implements a <strong>Prisoner&rsquo;s Dilemma</strong> game between two AI agents.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">nashpy</span> <span class="k">as</span> <span class="nn">nash</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define the payoff matrix for Prisoner&#39;s Dilemma</span>
</span></span><span class="line"><span class="cl"><span class="n">P1_payoffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]])</span>  <span class="c1"># Row player (Agent 1)</span>
</span></span><span class="line"><span class="cl"><span class="n">P2_payoffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]])</span>  <span class="c1"># Column player (Agent 2)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create a game using Nashpy</span>
</span></span><span class="line"><span class="cl"><span class="n">game</span> <span class="o">=</span> <span class="n">nash</span><span class="o">.</span><span class="n">Game</span><span class="p">(</span><span class="n">P1_payoffs</span><span class="p">,</span> <span class="n">P2_payoffs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Compute Nash Equilibria</span>
</span></span><span class="line"><span class="cl"><span class="n">equilibria</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">game</span><span class="o">.</span><span class="n">support_enumeration</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Display Nash Equilibrium Strategies</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Nash Equilibria (Mixed Strategies):&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">eq</span> <span class="ow">in</span> <span class="n">equilibria</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Agent 1 Strategy: </span><span class="si">{</span><span class="n">eq</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, Agent 2 Strategy: </span><span class="si">{</span><span class="n">eq</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="explanation-1"><strong>Explanation:</strong></h4>
<ul>
<li>Models two <strong>self-interested agents</strong> choosing <strong>cooperate (C) or defect (D)</strong>.</li>
<li><strong>Nash equilibrium</strong> represents the <strong>optimal mixed strategies</strong>.</li>
</ul>
<hr>
<h3 id="3-decentralized-multi-agent-system-with-communication"><strong>3. Decentralized Multi-Agent System with Communication</strong></h3>
<p>A <strong>swarm of agents</strong> moves towards a goal using <strong>decentralized coordination</strong>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Environment settings</span>
</span></span><span class="line"><span class="cl"><span class="n">NUM_AGENTS</span> <span class="o">=</span> <span class="mi">10</span>
</span></span><span class="line"><span class="cl"><span class="n">GOAL</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">MOVE_STEP</span> <span class="o">=</span> <span class="mf">0.5</span>
</span></span><span class="line"><span class="cl"><span class="n">COMMUNICATION_RANGE</span> <span class="o">=</span> <span class="mf">2.0</span>
</span></span><span class="line"><span class="cl"><span class="n">ITERATIONS</span> <span class="o">=</span> <span class="mi">50</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Initialize agent positions randomly</span>
</span></span><span class="line"><span class="cl"><span class="n">agents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">NUM_AGENTS</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">move_towards_goal</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span> <span class="n">neighbors</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Compute average neighbor position (consensus rule)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">neighbors</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">avg_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">move_direction</span> <span class="o">=</span> <span class="n">avg_pos</span> <span class="o">-</span> <span class="n">agent</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">move_direction</span> <span class="o">=</span> <span class="n">GOAL</span> <span class="o">-</span> <span class="n">agent</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">agent</span> <span class="o">+</span> <span class="n">MOVE_STEP</span> <span class="o">*</span> <span class="p">(</span><span class="n">move_direction</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">move_direction</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Simulation</span>
</span></span><span class="line"><span class="cl"><span class="n">positions</span> <span class="o">=</span> <span class="p">[</span><span class="n">agents</span><span class="o">.</span><span class="n">copy</span><span class="p">()]</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ITERATIONS</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">new_positions</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">agents</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">neighbors</span> <span class="o">=</span> <span class="p">[</span><span class="n">other</span> <span class="k">for</span> <span class="n">other</span> <span class="ow">in</span> <span class="n">agents</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">agent</span> <span class="o">-</span> <span class="n">other</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">COMMUNICATION_RANGE</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">new_positions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">move_towards_goal</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span> <span class="n">neighbors</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">agents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_positions</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">positions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">agents</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Plot results</span>
</span></span><span class="line"><span class="cl"><span class="n">positions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">positions</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_AGENTS</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">positions</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">positions</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">GOAL</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">GOAL</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&#34;X&#34;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&#34;red&#34;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;Goal&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;X Position&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;Y Position&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;Swarm Agents Moving Towards Goal&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><h4 id="explanation-2"><strong>Explanation:</strong></h4>
<ul>
<li><strong>10 agents</strong> move towards a <strong>goal</strong> using <strong>local communication</strong>.</li>
<li><strong>Consensus-based movement</strong> makes it <strong>robust</strong> to missing data.</li>
<li>Models <strong>swarm robotics, decentralized AI, and self-organizing systems</strong>.</li>
</ul>
<hr>
<h3 id="4-reinforcement-learning-for-multi-agent-traffic-control"><strong>4. Reinforcement Learning for Multi-Agent Traffic Control</strong></h3>
<p>A <strong>multi-agent reinforcement learning</strong> setup where <strong>traffic lights learn</strong> optimal control.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">random</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Environment setup</span>
</span></span><span class="line"><span class="cl"><span class="n">ACTIONS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;RED&#34;</span><span class="p">,</span> <span class="s2">&#34;GREEN&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">TRAFFIC_STATES</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;LOW&#34;</span><span class="p">,</span> <span class="s2">&#34;MEDIUM&#34;</span><span class="p">,</span> <span class="s2">&#34;HIGH&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">Q_table</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">TRAFFIC_STATES</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ACTIONS</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Learning parameters</span>
</span></span><span class="line"><span class="cl"><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>
</span></span><span class="line"><span class="cl"><span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.9</span>
</span></span><span class="line"><span class="cl"><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.1</span>
</span></span><span class="line"><span class="cl"><span class="n">episodes</span> <span class="o">=</span> <span class="mi">5000</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Reward function (based on congestion reduction)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">reward</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">state</span> <span class="o">==</span> <span class="s2">&#34;HIGH&#34;</span> <span class="ow">and</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&#34;GREEN&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">10</span>  <span class="c1"># Best action</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="n">state</span> <span class="o">==</span> <span class="s2">&#34;LOW&#34;</span> <span class="ow">and</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&#34;RED&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">5</span>  <span class="c1"># Minor reward</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="o">-</span><span class="mi">5</span>  <span class="c1"># Wrong action penalty</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Training</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">episodes</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">state_idx</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">TRAFFIC_STATES</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Choose action (Œµ-greedy)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">action_idx</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ACTIONS</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">action_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q_table</span><span class="p">[</span><span class="n">state_idx</span><span class="p">,</span> <span class="p">:])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Get reward</span>
</span></span><span class="line"><span class="cl">    <span class="n">r</span> <span class="o">=</span> <span class="n">reward</span><span class="p">(</span><span class="n">TRAFFIC_STATES</span><span class="p">[</span><span class="n">state_idx</span><span class="p">],</span> <span class="n">ACTIONS</span><span class="p">[</span><span class="n">action_idx</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Update Q-table</span>
</span></span><span class="line"><span class="cl">    <span class="n">Q_table</span><span class="p">[</span><span class="n">state_idx</span><span class="p">,</span> <span class="n">action_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">r</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Q_table</span><span class="p">[</span><span class="n">state_idx</span><span class="p">,</span> <span class="p">:])</span> <span class="o">-</span> <span class="n">Q_table</span><span class="p">[</span><span class="n">state_idx</span><span class="p">,</span> <span class="n">action_idx</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Multi-Agent Traffic Control Training Complete!&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Final Q-Table:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">Q_table</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="explanation-3"><strong>Explanation:</strong></h4>
<ul>
<li><strong>Traffic signals</strong> learn <strong>optimal switching</strong> using <strong>Q-learning</strong>.</li>
<li><strong>Adaptive control</strong> based on <strong>real-time congestion</strong>.</li>
</ul>
<hr>
<h2 id="conclusion"><strong>Conclusion</strong></h2>
<p>These <strong>multi-agent system implementations</strong> provide:</p>
<ol>
<li><strong>Reinforcement Learning (Q-learning)</strong> ‚Äì AI agents learning in a <strong>shared environment</strong>.</li>
<li><strong>Game Theory (Nash Equilibrium)</strong> ‚Äì Competitive or cooperative decision-making.</li>
<li><strong>Decentralized Coordination</strong> ‚Äì Swarm behavior using <strong>local communication</strong>.</li>
<li><strong>Traffic Optimization</strong> ‚Äì AI-based <strong>autonomous traffic control</strong>.</li>
</ol>
<p>These techniques can be used for <strong>robotics, cybersecurity, and distributed AI</strong> applications. üöÄ</p>

      </div>

      
  <time class="mt-12 mb-8 block text-xs text-gray-500 ltr:text-right rtl:text-left dark:text-gray-400" datetime="2025-02-11T00:00:00.000Z">
    <span>Last updated on</span>
    Feb 11, 2025</time>

      <div class="container mx-auto prose prose-slate lg:prose-xl dark:prose-invert mt-5">
        
        <div class="max-w-prose print:hidden">
  
  

  

<div class="flex justify-center">
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/agentic-ai/">Agentic AI</a>
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/cybersecurity/">CyberSecurity</a>
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/threat-model/">Threat Model</a>
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/autonomous-systems/">Autonomous Systems</a>
  
</div>


  
<section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="https://twitter.com/intent/tweet?url=http%3A%2F%2Flocalhost%3A1313%2Fproject%2Fagentic%2F&amp;text=Multi-Agent&#43;AI&#43;Systems"
    title="X"
    aria-label="X"
    id="share-link-x"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
  </a>
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="https://www.facebook.com/sharer.php?u=http%3A%2F%2Flocalhost%3A1313%2Fproject%2Fagentic%2F&amp;t=Multi-Agent&#43;AI&#43;Systems"
    title="Facebook"
    aria-label="Facebook"
    id="share-link-facebook"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="currentColor" d="M22 12c0-5.52-4.48-10-10-10S2 6.48 2 12c0 4.84 3.44 8.87 8 9.8V15H8v-3h2V9.5C10 7.57 11.57 6 13.5 6H16v3h-2c-.55 0-1 .45-1 1v2h3v3h-3v6.95c5.05-.5 9-4.76 9-9.95z"/></svg>
  </a>
  

  
  
  
  
  
  
    
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="mailto:?subject=Multi-Agent%20AI%20Systems&amp;body=http%3A%2F%2Flocalhost%3A1313%2Fproject%2Fagentic%2F"
    title="Email"
    aria-label="Email"
    id="share-link-email"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5 0 1 1-9 0a4.5 4.5 0 0 1 9 0Zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 1 0-2.636 6.364M16.5 12V8.25"/></svg>
  </a>
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="https://www.linkedin.com/shareArticle?url=http%3A%2F%2Flocalhost%3A1313%2Fproject%2Fagentic%2F&amp;title=Multi-Agent&#43;AI&#43;Systems"
    title="LinkedIn"
    aria-label="LinkedIn"
    id="share-link-linkedin"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
  </a>
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="whatsapp://send?text=Multi-Agent&#43;AI&#43;Systems%20http%3A%2F%2Flocalhost%3A1313%2Fproject%2Fagentic%2F"
    title="WhatsApp"
    aria-label="WhatsApp"
    id="share-link-whatsapp"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256" fill="currentColor"><path d="m187.58 144.84-32-16a8 8 0 0 0-8 .5l-14.69 9.8a40.55 40.55 0 0 1-16-16l9.8-14.69a8 8 0 0 0 .5-8l-16-32A8 8 0 0 0 104 64a40 40 0 0 0-40 40 88.1 88.1 0 0 0 88 88 40 40 0 0 0 40-40 8 8 0 0 0-4.42-7.16ZM152 176a72.08 72.08 0 0 1-72-72 24 24 0 0 1 19.29-23.54l11.48 23L101 118a8 8 0 0 0-.73 7.51 56.47 56.47 0 0 0 30.15 30.15A8 8 0 0 0 138 155l14.61-9.74 23 11.48A24 24 0 0 1 152 176ZM128 24a104 104 0 0 0-91.82 152.88l-11.35 34.05a16 16 0 0 0 20.24 20.24l34.05-11.35A104 104 0 1 0 128 24Zm0 192a87.87 87.87 0 0 1-44.06-11.81 8 8 0 0 0-6.54-.67L40 216l12.47-37.4a8 8 0 0 0-.66-6.54A88 88 0 1 1 128 216Z"/></svg>
  </a>
  
</section>


  








  
  



  
  
  
    
  
  
  

<div class="flex pt-12 pb-4">
  
  
  <img
    class="mr-4 h-24 w-24 rounded-full"
    width="96"
    height="96"
    alt="Armstrong Foundjem"
  src="/author/armstrong-foundjem/avatar_hu_c3957f84e9970bb0.jpeg"
  loading="lazy"
  />
  
  <div class="place-self-center">
    <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
      Authors
    </div>
    <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
      <a href="http://localhost:1313/" class="no-underline">
      Armstrong Foundjem
      </a>
    </div>

    
    <div class="text-sm font-bold text-neutral-700 dark:text-neutral-300">
    Chief Scientist
    </div>
    


    

    <div class="text-2xl sm:text-lg pt-1">

      
<div class="flex flex-wrap text-neutral-500 dark:text-neutral-300">
  
    
    
    
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="mailto:foundjem@ieee.org"
      
      aria-label="At-Symbol"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5 0 1 1-9 0a4.5 4.5 0 0 1 9 0Zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 1 0-2.636 6.364M16.5 12V8.25"/></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://twitter.com/foundjem"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Brands/X"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://www.instagram.com/"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Brands/Instagram"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15 15"><path fill="currentColor" fill-rule="evenodd" d="M12.91 12.909c.326-.327.582-.72.749-1.151c.16-.414.27-.886.302-1.578c.032-.693.04-.915.04-2.68c0-1.765-.008-1.987-.04-2.68c-.032-.692-.142-1.164-.302-1.578a3.185 3.185 0 0 0-.75-1.151a3.187 3.187 0 0 0-1.151-.75c-.414-.16-.886-.27-1.578-.302C9.487 1.007 9.265 1 7.5 1c-1.765 0-1.987.007-2.68.04c-.692.03-1.164.14-1.578.301a3.2 3.2 0 0 0-1.151.75a3.2 3.2 0 0 0-.75 1.151c-.16.414-.27.886-.302 1.578C1.007 5.513 1 5.735 1 7.5c0 1.765.007 1.987.04 2.68c.03.692.14 1.164.301 1.578c.164.434.42.826.75 1.151c.325.33.718.586 1.151.75c.414.16.886.27 1.578.302c.693.031.915.039 2.68.039c1.765 0 1.987-.008 2.68-.04c.692-.03 1.164-.14 1.578-.301a3.323 3.323 0 0 0 1.151-.75ZM2 6.735v1.53c-.002.821-.002 1.034.02 1.5c.026.586.058 1.016.156 1.34c.094.312.199.63.543 1.012c.344.383.675.556 1.097.684c.423.127.954.154 1.415.175c.522.024.73.024 1.826.024H8.24c.842.001 1.054.002 1.526-.02c.585-.027 1.015-.059 1.34-.156c.311-.094.629-.2 1.011-.543c.383-.344.556-.676.684-1.098c.127-.422.155-.953.176-1.414C13 9.247 13 9.04 13 7.947v-.89c0-1.096 0-1.303-.023-1.826c-.021-.461-.049-.992-.176-1.414c-.127-.423-.3-.754-.684-1.098c-.383-.344-.7-.449-1.011-.543c-.325-.097-.755-.13-1.34-.156A27.29 27.29 0 0 0 8.24 2H7.057c-1.096 0-1.304 0-1.826.023c-.461.021-.992.049-1.415.176c-.422.128-.753.301-1.097.684c-.344.383-.45.7-.543 1.012c-.098.324-.13.754-.156 1.34c-.022.466-.022.679-.02 1.5ZM7.5 5.25a2.25 2.25 0 1 0 0 4.5a2.25 2.25 0 0 0 0-4.5ZM4.25 7.5a3.25 3.25 0 1 1 6.5 0a3.25 3.25 0 0 1-6.5 0Zm6.72-2.72a.75.75 0 1 0 0-1.5a.75.75 0 0 0 0 1.5Z" clip-rule="evenodd"/></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://github.com/foundjem"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Brands/Github"
    ><svg style="height: 1em;" fill="currentColor" viewBox="3 3 18 18"><path d="M12 3C7.0275 3 3 7.12937 3 12.2276C3 16.3109 5.57625 19.7597 9.15374 20.9824C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441C9.77249 20.3249 9.76125 19.5982 9.76125 18.8254C7.5 19.2522 6.915 18.2602 6.735 17.7412C6.63375 17.4759 6.19499 16.6569 5.8125 16.4378C5.4975 16.2647 5.0475 15.838 5.80124 15.8264C6.51 15.8149 7.01625 16.4954 7.18499 16.7723C7.99499 18.1679 9.28875 17.7758 9.80625 17.5335C9.885 16.9337 10.1212 16.53 10.38 16.2993C8.3775 16.0687 6.285 15.2728 6.285 11.7432C6.285 10.7397 6.63375 9.9092 7.20749 9.26326C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794C7.2975 6.81794 8.05125 6.57571 9.77249 7.76377C10.4925 7.55615 11.2575 7.45234 12.0225 7.45234C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377C15.9937 6.56418 16.7475 6.81794 16.7475 6.81794C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326C17.4113 9.9092 17.76 10.7281 17.76 11.7432C17.76 15.2843 15.6563 16.0687 13.6537 16.2993C13.98 16.5877 14.2613 17.1414 14.2613 18.0065C14.2613 19.2407 14.25 20.2326 14.25 20.5441C14.25 20.7863 14.4188 21.0746 14.8688 20.9824C16.6554 20.364 18.2079 19.1866 19.3078 17.6162C20.4077 16.0457 20.9995 14.1611 21 12.2276C21 7.12937 16.9725 3 12 3Z"></path></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://www.linkedin.com/in/foundjem/"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Brands/Linkedin"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://scholar.google.com/citations?user=0cVPd2QAAAAJ&amp;hl=en"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Academicons/Google-Scholar"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M343.759 106.662V79.43L363.524 64h-213.89L20.476 176.274h85.656a82.339 82.339 0 0 0-.219 6.225c0 20.845 7.22 38.087 21.672 51.861c14.453 13.797 32.252 20.648 53.327 20.648c4.923 0 9.75-.368 14.438-1.024c-2.907 6.5-4.374 12.523-4.374 18.142c0 9.875 4.499 20.43 13.467 31.642c-39.234 2.67-68.061 9.732-86.437 21.163c-10.531 6.5-19 14.704-25.39 24.531c-6.391 9.9-9.578 20.515-9.578 31.962c0 9.648 2.062 18.336 6.219 26.062c4.156 7.726 9.578 14.07 16.312 18.984c6.718 4.968 14.469 9.101 23.219 12.469c8.734 3.344 17.406 5.718 26.061 7.062A167.052 167.052 0 0 0 180.555 448c13.469 0 26.953-1.734 40.547-5.187c13.562-3.485 26.28-8.642 38.171-15.493c11.86-6.805 21.515-16.086 28.922-27.718c7.39-11.68 11.094-24.805 11.094-39.336c0-11.016-2.25-21.039-6.75-30.14c-4.468-9.073-9.938-16.542-16.452-22.345c-6.501-5.813-13-11.155-19.516-15.968c-6.5-4.845-12-9.75-16.468-14.813c-4.485-5.046-6.735-10.054-6.735-14.984c0-4.921 1.734-9.672 5.216-14.265c3.455-4.61 7.674-9.048 12.61-13.306c4.937-4.25 9.875-8.968 14.796-14.133c4.922-5.147 9.141-11.827 12.61-20.008c3.485-8.18 5.203-17.445 5.203-27.757c0-13.453-2.547-24.46-7.547-33.314c-.594-1.022-1.218-1.803-1.875-3.022l56.907-46.672v17.119c-7.393.93-6.624 5.345-6.624 10.635V245.96c0 5.958 4.875 10.834 10.834 10.834h3.989c5.958 0 10.833-4.875 10.833-10.834V117.293c0-5.277.778-9.688-6.561-10.63zm-107.36 222.48c1.14.75 3.704 2.78 7.718 6.038c4.05 3.243 6.797 5.695 8.266 7.414a443.553 443.553 0 0 1 6.376 7.547c2.813 3.375 4.718 6.304 5.718 8.734c1 2.477 2.016 5.461 3.047 8.946a38.27 38.27 0 0 1 1.485 10.562c0 17.048-6.564 29.68-19.656 37.859c-13.125 8.18-28.767 12.274-46.938 12.274c-9.187 0-18.203-1.093-27.063-3.196c-8.843-2.116-17.311-5.336-25.39-9.601c-8.078-4.258-14.577-10.204-19.5-17.797c-4.938-7.64-7.407-16.415-7.407-26.25c0-10.32 2.797-19.29 8.422-26.906c5.594-7.625 12.938-13.391 22.032-17.315c9.063-3.946 18.25-6.742 27.562-8.398a157.865 157.865 0 0 1 28.438-2.555c4.47 0 7.936.25 10.405.696c.455.219 3.032 2.07 7.735 5.563c4.704 3.462 7.625 5.595 8.75 6.384zm-3.359-100.579c-7.406 8.86-17.734 13.288-30.953 13.288c-11.86 0-22.298-4.764-31.266-14.312c-9-9.523-15.422-20.328-19.344-32.43c-3.937-12.109-5.906-23.984-5.906-35.648c0-13.694 3.596-25.352 10.781-34.976c7.187-9.65 17.5-14.485 30.938-14.485c11.875 0 22.374 5.038 31.437 15.157c9.094 10.085 15.61 21.413 19.517 33.968c3.922 12.54 5.873 24.53 5.873 35.984c0 13.446-3.702 24.61-11.076 33.454z"/></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://orcid.org/0000-0001-6356-1938"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Academicons/Orcid"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M336.62 194.538c-7.13-3.328-13.866-5.56-20.253-6.614c-6.365-1.095-16.574-1.612-30.71-1.612h-36.704v152.747h37.634c14.673 0 26.081-1.013 34.224-3.017c8.142-2.004 14.921-4.526 20.356-7.626a69.448 69.448 0 0 0 14.942-11.388c14.488-14.714 21.742-33.273 21.742-55.717c0-22.052-7.44-40.052-22.341-53.982c-5.498-5.166-11.822-9.444-18.89-12.793zM256 8C119.022 8 8 119.042 8 256s111.022 248 248 248s248-111.042 248-248S392.978 8 256 8Zm-82.336 357.513h-29.389V160.148h29.389zM158.95 138.696c-11.14 0-20.213-9.01-20.213-20.212c0-11.118 9.052-20.191 20.213-20.191c11.18 0 20.232 9.052 20.232 20.191a20.194 20.194 0 0 1-20.232 20.212zm241.386 163.597c-5.29 12.545-12.834 23.581-22.65 33.088c-9.982 9.837-21.597 17.194-34.844 22.196c-7.75 3.017-14.839 5.063-21.307 6.117c-6.49 1.013-18.828 1.509-37.076 1.509h-64.956V160.148h69.233c27.962 0 50.034 4.154 66.32 12.545c16.265 8.37 29.181 20.728 38.792 36.972c9.61 16.265 14.425 34.018 14.425 53.196c.023 13.765-2.666 26.908-7.936 39.432z"/></svg></a>
  
</div>



    </div>
  </div>
</div>







  
  
    
    
    
      
      
    
<div class="pt-1 no-prose w-full">
  <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
  <div class="flex flex-col md:flex-row flex-nowrap justify-between gap-5 pt-2">
    <div class="">
      
    </div>
    <div class="">
      
        <a class="group flex text-right no-underline" href="/project/climate-change/">
          <span class="flex flex-col">
            <span
              class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
            >Climate change</span
            >
            <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
              
                Jan 26, 2025
              
            </span>
          </span>
          <span
            class="mt-[-0.3rem] ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
          ><span class="ltr:inline">&rarr;</span></span>
        </a>
      
    </div>
  </div>
</div>



  


  



</div>

      </div>

    </main>
  </article>
</div>

    </div>
    <div class="page-footer">
      <footer class="container mx-auto flex flex-col justify-items-center text-sm leading-6 mt-24 mb-4 text-slate-700 dark:text-slate-200">

  












  
  
  
  
  














  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by text-center">
    ¬© 2025 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by text-center">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> ‚Äî the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>

</footer>

    </div>

    
    











  </body>
</html>
